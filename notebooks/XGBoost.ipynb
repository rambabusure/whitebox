{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "\n",
    "from yellowbrick.features import ParallelCoordinates, Rank2D, JointPlotVisualizer, RadViz, Rank1D\n",
    "from yellowbrick.model_selection import FeatureImportances\n",
    "from yellowbrick.classifier import ClassificationReport, ROCAUC, ClassPredictionError\n",
    "from yellowbrick.cluster import SilhouetteVisualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../titanic_data/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Cabin_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Cabin Embarked  \\\n",
       "0         0       3    male  22.0      1      0   7.2500   NaN        S   \n",
       "1         1       1  female  38.0      1      0  71.2833   C85        C   \n",
       "2         1       3  female  26.0      0      0   7.9250   NaN        S   \n",
       "3         1       1  female  35.0      1      0  53.1000  C123        S   \n",
       "4         0       3    male  35.0      0      0   8.0500   NaN        S   \n",
       "\n",
       "  Cabin_Class  \n",
       "0          na  \n",
       "1           C  \n",
       "2          na  \n",
       "3           C  \n",
       "4          na  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Cabin_Class'] = df['Cabin'].str[0]\n",
    "df['Cabin_Class'] = df['Cabin_Class'].fillna('na')\n",
    "\n",
    "df['Embarked'] = df['Embarked'].astype(str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "se = LabelEncoder().fit(df['Sex'])\n",
    "ee = LabelEncoder().fit(df['Embarked'])\n",
    "ce = LabelEncoder().fit(df['Cabin_Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Cabin', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(max_depth=len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sex'] = se.transform(df['Sex'])\n",
    "df['Embarked'] = ee.transform(df['Embarked'])\n",
    "df['Cabin_Class'] = ce.transform(df['Cabin_Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Cabin_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked  Cabin_Class\n",
       "0         0       3    1  22.0      1      0   7.2500         2            8\n",
       "1         1       1    0  38.0      1      0  71.2833         0            2\n",
       "2         1       3    0  26.0      0      0   7.9250         2            8\n",
       "3         1       1    0  35.0      1      0  53.1000         2            2\n",
       "4         0       3    1  35.0      0      0   8.0500         2            8"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Survived', axis=1)\n",
    "y = df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning:\n",
      "\n",
      "Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = X_train.as_matrix(), X_test.as_matrix(), y_train.as_matrix(), y_test.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.    ,  1.    , 28.    , ..., 47.1   ,  2.    ,  8.    ],\n",
       "       [ 3.    ,  0.    , 30.    , ...,  8.6625,  2.    ,  8.    ],\n",
       "       [ 3.    ,  1.    , 22.    , ...,  8.05  ,  2.    ,  8.    ],\n",
       "       ...,\n",
       "       [ 2.    ,  1.    , 50.    , ..., 13.    ,  2.    ,  8.    ],\n",
       "       [ 3.    ,  1.    , 21.    , ...,  7.7333,  1.    ,  8.    ],\n",
       "       [ 1.    ,  1.    , 47.    , ..., 25.5875,  2.    ,  4.    ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.91      0.85       123\n",
      "           1       0.85      0.68      0.76        92\n",
      "\n",
      "    accuracy                           0.81       215\n",
      "   macro avg       0.82      0.80      0.80       215\n",
      "weighted avg       0.82      0.81      0.81       215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('./model_rachel.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "import lime.lime_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(training_data=X_train, \n",
    "                                                   mode='classification',  \n",
    "                                                   feature_names=X.columns, class_names=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = X_test[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(t, model.predict_proba, num_features=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.show_in_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Plot\n",
    "model.predict_proba([t])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_proba([t])\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viz 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_probability_chart(pred):\n",
    "    \"\"\"\n",
    "    Generates a bar chart showing the probability of each class\n",
    "    :param pred: output of predict_proba function\n",
    "    \"\"\"\n",
    "    # convert passed predictions to numpy array\n",
    "    npred = np.array(pred)\n",
    "    \n",
    "    # grabs the number of classes\n",
    "    if len(npred.shape) < 2:  # fix for instance where a single list is passed\n",
    "        npred = npred.reshape(1, -1)\n",
    "    \n",
    "    num_classes = npred.shape[1]\n",
    "    npred = pred.reshape(num_classes,)\n",
    "    \n",
    "    layout = go.Layout(title='Class Probabilities')\n",
    "    fig_ = go.Figure(layout=layout)\n",
    "    \n",
    "    for c in range(num_classes):\n",
    "        fig_.add_trace(go.Bar(\n",
    "            x = [f'class_{c}'],\n",
    "            y = [npred[c]],\n",
    "            name=f'class_{c}', \n",
    "        ))\n",
    "        \n",
    "    return fig_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iplot(\n",
    "    generate_probability_chart(pred)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.local_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viz 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_exp_df(exp_, feature_names=X.columns):\n",
    "    \"\"\"\n",
    "    Given a lime_explainer.local_exp object returns the cleaned version in a dataframe\n",
    "    :param exp: lime_explainer.local_exp result\n",
    "    \"\"\"\n",
    "    new_exp = dict(exp_)\n",
    "    p2g = {}\n",
    "\n",
    "    for k in new_exp.keys():\n",
    "        p2g[feature_names[k]] = new_exp[k]\n",
    "        \n",
    "    p2g = pd.DataFrame(p2g, index=[0]).T.reset_index()\n",
    "    p2g.columns = ['feature', 'value']\n",
    "    return p2g.sort_values(by='value')\n",
    "\n",
    "lexp = local_exp_df(exp.local_exp[1])\n",
    "lexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_feature_importance(data, model, feature_names=X.columns):\n",
    "    \"\"\"\n",
    "    Given a row of data to be evaluate and a model to do the evaluation with, \n",
    "    returns a plot showing the local feature importance of each feature\n",
    "    \n",
    "    :param data: array of data, output of .predict()\n",
    "    \"\"\"\n",
    "    xdata = np.array(data)\n",
    "    num_features = len(xdata)\n",
    "    \n",
    "    exp = explainer.explain_instance(xdata, model.predict_proba, num_features=num_features)\n",
    "    new_exp = dict(exp.local_exp[1])\n",
    "    \n",
    "    p2g = {}\n",
    "\n",
    "    for k in new_exp.keys():\n",
    "        p2g[feature_names[k]] = new_exp[k]\n",
    "        \n",
    "    viz = go.Bar(\n",
    "        x = list(p2g.values()),\n",
    "        y = list(p2g.keys()),\n",
    "        name='feature values', \n",
    "        orientation='h'\n",
    "    )\n",
    "\n",
    "    layout = go.Layout(title='Feature Importance')\n",
    "    fig = go.Figure([viz], layout)\n",
    "        \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iplot(\n",
    "    local_feature_importance(t, model=model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third Visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.domain_mapper.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.domain_mapper.feature_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_values(data, model, feature_names=X.columns):\n",
    "    \"\"\"\n",
    "    Given a row of data to be evaluate and a model to do the evaluation with, \n",
    "    returns a plot showing the feature values\n",
    "    \n",
    "    :param data: array of data, output of .predict()\n",
    "    \"\"\"\n",
    "    xdata = np.array(data)\n",
    "    num_features = len(xdata)\n",
    "    \n",
    "    exp = explainer.explain_instance(xdata, model.predict_proba, num_features=num_features)\n",
    "    \n",
    "    feature_names = exp.domain_mapper.feature_names\n",
    "    feature_values = exp.domain_mapper.feature_values\n",
    "    \n",
    "    table = go.Figure(\n",
    "        go.Table(\n",
    "            header=dict(values=['Feature', 'Value']),\n",
    "            cells=dict(values=[feature_names, feature_values])\n",
    "        )\n",
    "    )\n",
    "    return table\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_values(t, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lime(object):\n",
    "    \n",
    "    def __init__(self, model, feature_names, modeling_task=None, classes=None):\n",
    "        self.model = model\n",
    "        self.feature_names = feature_names\n",
    "        self.modeling_task = 'classification' if modeling_task is None else 'regression'\n",
    "        self.classes = None\n",
    "        self.num_classes = None\n",
    "        \n",
    "        if self.modeling_task == 'classification':\n",
    "            self.classes = np.array(classes)\n",
    "            self.num_classes = self.classes.shape[0]\n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "    def generate_probability_chart(self, data):\n",
    "        \"\"\"\n",
    "        Generates a bar chart showing the probability of each class\n",
    "        :param pred: output of predict_proba function\n",
    "        \"\"\"\n",
    "        # convert passed predictions to numpy array\n",
    "        xdata = np.array(data)\n",
    "\n",
    "        # grabs the number of classes\n",
    "        if len(xdata.shape) < 2:  # fix for instance where a single list is passed\n",
    "            xdata = xdata.reshape(1, -1)\n",
    "\n",
    "        pred = self.model.predict_proba(xdata)\n",
    "        \n",
    "        num_classes = pred.shape[1]\n",
    "        npred = pred.reshape(num_classes,)\n",
    "\n",
    "        layout = go.Layout(title='Class Probabilities')\n",
    "        fig_ = go.Figure(layout=layout)\n",
    "\n",
    "        for c in range(num_classes):\n",
    "            if {self.classes[c]}:\n",
    "                fig_.add_trace(go.Bar(\n",
    "                    x = [f'{self.classes[c]}'],\n",
    "                    y = [npred[c]],\n",
    "                    name=f'{self.classes[c]}', \n",
    "                ))\n",
    "            else:\n",
    "                fig_.add_trace(go.Bar(\n",
    "                    x = [f'class_{c}'],\n",
    "                    y = [npred[c]],\n",
    "                    name=f'class_{c}', \n",
    "                ))\n",
    "                \n",
    "        return fig_\n",
    "\n",
    "    \n",
    "    def local_feature_importance(self, data):\n",
    "        \"\"\"\n",
    "        Given a row of data to be evaluate and a model to do the evaluation with, \n",
    "        returns a plot showing the local feature importance of each feature\n",
    "\n",
    "        :param data: array of data, output of .predict()\n",
    "        \"\"\"\n",
    "        xdata = np.array(data)\n",
    "        num_features = xdata.shape[0]\n",
    "\n",
    "        exp = explainer.explain_instance(xdata, self.model.predict_proba, num_features=num_features)\n",
    "        new_exp = dict(exp.local_exp[1])\n",
    "\n",
    "        p2g = {}\n",
    "\n",
    "        for k in new_exp.keys():\n",
    "            p2g[self.feature_names[k]] = new_exp[k]\n",
    "            \n",
    "        colors = ['rgb(255,92,92)' if val < 0 else 'rgb(92,92,255)' for val in p2g.values()]\n",
    "\n",
    "        viz = go.Bar(\n",
    "            x = list(p2g.values()),\n",
    "            y = list(p2g.keys()),\n",
    "            name='feature values', \n",
    "            orientation='h',\n",
    "            marker=dict(color=colors)\n",
    "        )\n",
    "\n",
    "        layout = go.Layout(title='Feature Importance')\n",
    "        fig = go.Figure([viz], layout)\n",
    "\n",
    "        return fig\n",
    "\n",
    "\n",
    "    def feature_values(self, data):\n",
    "        \"\"\"\n",
    "        Given a row of data to be evaluate and a model to do the evaluation with, \n",
    "        returns a plot showing the feature values\n",
    "\n",
    "        :param data: array of data, output of .predict()\n",
    "        \"\"\"\n",
    "        xdata = np.array(data)\n",
    "        num_features = len(xdata)\n",
    "\n",
    "        exp = explainer.explain_instance(xdata, self.model.predict_proba, num_features=num_features)\n",
    "\n",
    "        feature_names = exp.domain_mapper.feature_names\n",
    "        feature_values = exp.domain_mapper.feature_values\n",
    "\n",
    "        table = go.Figure(\n",
    "            go.Table(\n",
    "                header=dict(values=['Feature', 'Value']),\n",
    "                cells=dict(values=[feature_names, feature_values])\n",
    "            )\n",
    "        )\n",
    "        return table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = Lime(model=model, feature_names=X.columns, classes=['not_survived', 'survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l.local_feature_importance(X_test[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l.generate_probability_chart(X_test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l.feature_values(X_test[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yellowbricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = ParallelCoordinates()\n",
    "visualizer.fit_transform(X, y)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ParallelCoordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = ParallelCoordinates()\n",
    "visualizer.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(df.corrwith(df['Survived']).values.reshape(1, -1), \n",
    "            xticklabels=df.columns,\n",
    "            yticklabels=['Survived'],\n",
    "           annot=True, center=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = ClassificationReport(model)\n",
    "\n",
    "visualizer.fit(X_train, y_train)\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomVisuals(object):\n",
    "    \n",
    "    def __init__(self, model, feature_names, classes):\n",
    "        self.model = model\n",
    "        self.feature_names = feature_names\n",
    "        self.classes = classes\n",
    "        \n",
    "    def generate_classification_report(self, X_test, y_test, \n",
    "                                       zmin=0, zmax=1, annot=False, \n",
    "                                       **kwargs):\n",
    "        \"\"\"\n",
    "        Given the test data sets, produces a classification report and returns a plotly\n",
    "        Heatmap figure.\n",
    "        \n",
    "        :param X_test: The withheld input features from the training data set.\n",
    "        :param y_test: The withheld output target from the training data set.\n",
    "        :param zmin: (optional) sets scale minimum. Defaults to 0.\n",
    "        :param zmax: (optional) sets scale maxmimum. Defaults to 1.\n",
    "        \"\"\"\n",
    "        cr = classification_report(y_test, self.model.predict(X_test), output_dict=True)\n",
    "        cr = pd.DataFrame(cr)\n",
    "        \n",
    "        fig_x = self.classes + ['accuracy', 'macro avg', 'weighted avg']\n",
    "        fig_y = cr.index\n",
    "        z_text = cr.values\n",
    "        \n",
    "        fig = go.Figure(\n",
    "            go.Heatmap(\n",
    "                z = cr.values,\n",
    "                x = fig_x,\n",
    "                y = fig_y,\n",
    "                zmin = zmin if zmin is not None else zmin,\n",
    "                zmax = zmax if zmax is not None else zmax,\n",
    "                text = None if annot == False else z_text,\n",
    "                **kwargs\n",
    "            )\n",
    "        )\n",
    "        return fig\n",
    "    def generate_confusion_matrix(self, X_test, y_test, **kwargs):\n",
    "        \"\"\"\n",
    "        Given the test data sets, produces a confusion matrixs and returns a \n",
    "        plotly Heatmap figure.\n",
    "        \n",
    "        :param X_test: The withheld input features from the training data set.\n",
    "        :param y_test: The withheld output target from the training data set.\n",
    "        \"\"\"\n",
    "        \n",
    "        cm = confusion_matrix(y_test, self.model.predict(X_test))\n",
    "        \n",
    "        fig_x = self.classes\n",
    "        fig_y = self.classes\n",
    "        fig_z = cm\n",
    "\n",
    "        hovertext = list()\n",
    "        for yi, yy in enumerate(fig_y):\n",
    "            hovertext.append(list())\n",
    "            for xi, xx in enumerate(fig_x):\n",
    "                hovertext[-1].append(f'Predicted: {xx}<br />Actual: {yy}<br />Count: {fig_z[yi][xi]}')\n",
    "      \n",
    "        fig = go.Figure(\n",
    "            go.Heatmap(\n",
    "                z = fig_z, \n",
    "                x = fig_x,\n",
    "                y = fig_y,\n",
    "                hoverinfo='text',\n",
    "                text=hovertext,\n",
    "                **kwargs\n",
    "            ),\n",
    "            go.Layout(\n",
    "                xaxis=go.layout.XAxis(\n",
    "                    title=go.layout.xaxis.Title(text='Predicted', font=dict(size=24))\n",
    "                ),\n",
    "                yaxis=go.layout.YAxis(\n",
    "                    title=go.layout.yaxis.Title(text='Actuals', font=dict(size=24))\n",
    "                )\n",
    "            \n",
    "            )\n",
    "        )\n",
    "        return fig\n",
    "    \n",
    "    \n",
    "\n",
    "    def generate_rank_2d(self, X, algorithm='pearson', **kwargs):\n",
    "        \"\"\"\n",
    "        Given the entire (train+test) input features, returns a plotly\n",
    "        Heatmap figure showing the feature x feature correlation.\n",
    "        \n",
    "        :param X: the input features to the model\n",
    "        :param algorithm: the algorithm to calculate the importance with \n",
    "                          (pearson, covariance, spearman, kendalltau)\n",
    "        \"\"\"\n",
    "        \n",
    "        visualizer = Rank2D(algorithm=algorithm)\n",
    "        visualizer.fit_transform(X)\n",
    "        \n",
    "        #grabbing feature shape\n",
    "        feats = ranks_.shape[0]\n",
    "        \n",
    "        # zero-ing out one of the diagonals features\n",
    "        iu = np.triu_indices(feats, )\n",
    "        ranks_[iu] = 0\n",
    "        \n",
    "        fig = go.Figure(\n",
    "            go.Heatmap(\n",
    "                z = ranks_,\n",
    "                x = visualizer.features_,\n",
    "                y = np.flip(visualizer.features_), \n",
    "                **kwargs\n",
    "                \n",
    "            )\n",
    "        )\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    \n",
    "    def generate_rank_1d(self, X, y, algorithm='shapiro', **kwargs):\n",
    "        \"\"\"\n",
    "        Given the entire (train+test) input and target features, returns \n",
    "        a plotly figure showing the feature correlation.\n",
    "        \n",
    "        :param X: the input features to the model\n",
    "        :param y: the target feature\n",
    "        \"\"\"\n",
    "        \n",
    "        visualizer = Rank1D(algorithm='shapiro')\n",
    "\n",
    "        visualizer.fit(X, y)           # Fit the data to the visualizer\n",
    "        visualizer.transform(X)        # Transform the data\n",
    "        \n",
    "        fig = go.Figure(\n",
    "            go.Bar(\n",
    "                x = visualizer.ranks_,\n",
    "                y = visualizer.features_,\n",
    "                orientation='h'\n",
    "            )\n",
    "        )\n",
    "        return fig\n",
    "        \n",
    "    def generate_rad_viz(self, X, y, **kwargs):\n",
    "        \"\"\"\n",
    "        Given the entire feature-space, X, and target-space, y, \n",
    "        generates a RadViz plotly object.\n",
    "        \n",
    "        :param X: the input features to the model.\n",
    "        :param y: the target variables to the model.\n",
    "        \"\"\"\n",
    "        \n",
    "        # grabbing rows, columns, to later build out the radviz data set\n",
    "        nrows, ncols = X.shape\n",
    "        to_plot = {label: [[], []] for label in yb.classes}\n",
    "        \n",
    "        # locations of where to plot the feature names.\n",
    "        class_points = np.array(\n",
    "            [\n",
    "                (np.cos(t), np.sin(t)) for t in [2.0 * np.pi * (i / float(ncols)) for i in range(ncols)]\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # converting from Data Frame to numpy array if need be\n",
    "        sc = MinMaxScaler(feature_range=(0,1))    \n",
    "        X_scaled = sc.fit_transform(X)\n",
    "        \n",
    "        # Compute the locations of the scatter plot for each class\n",
    "        for i, row in enumerate(X_scaled):\n",
    "            row_ = np.repeat(np.expand_dims(row, axis=1), 2, axis=1)\n",
    "            xy = (class_points * row_).sum(axis=0) / row.sum()\n",
    "            #label = self.classes[j] for j in y\n",
    "            label = self.classes[y.values[i]]\n",
    "            #label = 'not_survived' if y.values[i] == 0 else 'survived'  #self._label_encoder[y[i]]\n",
    "            to_plot[label][0].append(xy[0])\n",
    "            to_plot[label][1].append(xy[1])\n",
    "\n",
    "        layout = go.Layout(yaxis = dict(\n",
    "                            scaleanchor = \"x\",\n",
    "                            #scaleratio = 1,\n",
    "                            range=[-1.1, 1.1]\n",
    "                        ),\n",
    "                        xaxis=dict(\n",
    "                            range=[-1.1, 1.1],\n",
    "                            #scaleratio = 1\n",
    "                        ),\n",
    "                )\n",
    "\n",
    "        fig = go.Figure(layout=layout)\n",
    "            \n",
    "        for lab in self.classes:\n",
    "            trace = go.Scatter(\n",
    "                x = to_plot[lab][0],\n",
    "                y = to_plot[lab][1],\n",
    "                mode = 'markers', \n",
    "                name = f'{lab}'\n",
    "            )\n",
    "            fig.add_trace(trace)\n",
    "        \n",
    "\n",
    "        class_trace = go.Scatter(\n",
    "            x = [class_points[i][0] for i in range(len(class_points))] + [class_points[0][0]],\n",
    "            y = [class_points[i][1] for i in range(len(class_points))] + [class_points[0][1]],\n",
    "            name = 'Features',\n",
    "            mode = 'lines+text',\n",
    "            text = [self.feature_names[i] for i in range(len(self.feature_names))]\n",
    "        )\n",
    "        \n",
    "        fig.add_trace(class_trace)\n",
    "\n",
    "        return fig\n",
    "    \n",
    "    def generate_roc_auc(self, X_train, y_train, X_test, y_test, **kwargs):\n",
    "        \"\"\"\n",
    "        Given the training and testing sets, computes the ROC AUC metrics\n",
    "        for the given model and returns a ROC AUC plotly figure.\n",
    "        \n",
    "        :param X_train: the training feature set.\n",
    "        :param y_train: the training target set.\n",
    "        :param X_test: the testing feature set.\n",
    "        :param y_test: the testing target set.\n",
    "        \"\"\"\n",
    "        \n",
    "        visualizer = ROCAUC(self.model, classes=self.classes)\n",
    "\n",
    "        visualizer.fit(X_train, y_train)\n",
    "        visualizer.score(X_test, y_test)\n",
    "        \n",
    "        roc_data = visualizer.tpr\n",
    "        \n",
    "        layout = go.Layout(yaxis = dict(\n",
    "                                scaleratio = 1,\n",
    "                                range=[-.1, 1]\n",
    "                            ),\n",
    "                            xaxis=dict(\n",
    "                                range=[-.1, 1],\n",
    "                                #scaleratio = 1\n",
    "                            ),\n",
    "                        )\n",
    "\n",
    "        fig = go.Figure(layout=layout)\n",
    "\n",
    "        for tr in roc_data.keys():\n",
    "            trace = go.Scatter(\n",
    "                x = [i / len(roc_data[tr]) for i in range(len(roc_data[tr]))],\n",
    "                y = roc_data[tr],\n",
    "                name = f'{tr}' if type(tr) != int else f'{yb.classes[tr]}',\n",
    "                line = dict(shape = 'hv')\n",
    "            )\n",
    "            fig.add_trace(trace)\n",
    "\n",
    "        lin_line = go.Scatter(\n",
    "            x = [0,1],\n",
    "            y = [0,1],\n",
    "            name = 'linear_line',\n",
    "            line = dict(dash='dash')\n",
    "        )\n",
    "\n",
    "        fig.add_trace(lin_line)\n",
    "        return fig\n",
    "    \n",
    "    def generate_pca_2d(self, X, y, scale=True, **kwargs):\n",
    "        \"\"\"\n",
    "        Given the entire feature and target sets, performs a 2D Principal\n",
    "        Component Analysis and returns a plotly figure\n",
    "        \n",
    "        :param X: model feature set.\n",
    "        :param y: model target set.\n",
    "        :param scale: bool indicating if you want to perform Standard Scaling.\n",
    "        \"\"\"\n",
    "        \n",
    "        if scale:\n",
    "            X = StandardScaler().fit_transform(X)\n",
    "\n",
    "        model = PCA(n_components = 2)\n",
    "        model.fit(X)\n",
    "        features = model.transform(X) \n",
    "        \n",
    "        layout = go.Layout(\n",
    "            xaxis=dict(title='PC<sub>1</sub>'),\n",
    "            yaxis=dict(title='PC<sub>2</sub>')\n",
    "        )\n",
    "        \n",
    "        fig = go.Figure(layout=layout)\n",
    "        \n",
    "        for class_ in range(len(self.classes)):\n",
    "            temp_x, temp_y = features[y == class_].T\n",
    "            \n",
    "            trace = go.Scatter(\n",
    "                x = temp_x,\n",
    "                y = temp_y,\n",
    "                name = f'{self.classes[class_]}',\n",
    "                mode = 'markers'\n",
    "            )\n",
    "            \n",
    "            fig.add_trace(trace)\n",
    "    \n",
    "        return fig\n",
    "    \n",
    "    \n",
    "    def generate_pca_3d(self, X, y, scale=True, **kwargs):\n",
    "        \"\"\"\n",
    "        Given the entire feature and target sets, performs a 3D Principal\n",
    "        Component Analysis and returns a plotly figure\n",
    "        \n",
    "        :param X: model feature set.\n",
    "        :param y: model target set.\n",
    "        :param scale: bool indicating if you want to perform Standard Scaling.\n",
    "        \"\"\"\n",
    "        \n",
    "        if scale:\n",
    "            X = StandardScaler().fit_transform(X)\n",
    "\n",
    "        model = PCA(n_components = 3)\n",
    "        model.fit(X)\n",
    "        features = model.transform(X) \n",
    "        \n",
    "        fig = go.Figure()\n",
    "        \n",
    "        for class_ in range(len(self.classes)):\n",
    "            temp_x, temp_y, temp_z = features[y == class_].T\n",
    "            \n",
    "            trace = go.Scatter3d(\n",
    "                x = temp_x,\n",
    "                y = temp_y,\n",
    "                z = temp_z,\n",
    "                name = f'{self.classes[class_]}',\n",
    "                mode = 'markers'\n",
    "            )\n",
    "            \n",
    "            fig.add_trace(trace)\n",
    "            \n",
    "        \n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CustomVisuals(model=model, feature_names=X.columns, classes=['not_survived', 'survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cv.generate_classification_report(X_test, y_test, colorscale='Viridis', annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.generate_confusion_matrix(X_test, y_test, colorscale='Viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yellowbrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = Rank2D(algorithm='pearson')\n",
    "visualizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## values\n",
    "ranks_ = visualizer.ranks_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.ranking_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YellowBrick(object):\n",
    "    \n",
    "    def __init__(self, model, feature_names, classes):\n",
    "        self.model = model\n",
    "        self.feature_names = feature_names\n",
    "        self.classes = classes\n",
    "       \n",
    "    \n",
    "    def generate_rank_2d(self, X, algorithm='pearson', **kwargs):\n",
    "        \"\"\"\n",
    "        Given the entire (train+test) input features, returns a plotly\n",
    "        Heatmap figure showing the feature x feature correlation.\n",
    "        \n",
    "        :param X: the input features to the model\n",
    "        :param algorithm: the algorithm to calculate the importance with \n",
    "                          (pearson, covariance, spearman, kendalltau)\n",
    "        \"\"\"\n",
    "        \n",
    "        visualizer = Rank2D(algorithm=algorithm)\n",
    "        visualizer.fit_transform(X)\n",
    "        \n",
    "        #grabbing feature shape\n",
    "        feats = ranks_.shape[0]\n",
    "        \n",
    "        # zero-ing out one of the diagonals features\n",
    "        iu = np.triu_indices(feats, )\n",
    "        ranks_[iu] = 0\n",
    "        \n",
    "        fig = go.Figure(\n",
    "            go.Heatmap(\n",
    "                z = ranks_,\n",
    "                x = visualizer.features_,\n",
    "                y = np.flip(visualizer.features_), \n",
    "                **kwargs\n",
    "                \n",
    "            )\n",
    "        )\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    \n",
    "    def generate_rank_1d(self, X, y, algorithm='shapiro', **kwargs):\n",
    "        \"\"\"\n",
    "        Given the entire (train+test) input and target features, returns \n",
    "        a plotly figure showing the feature correlation.\n",
    "        \n",
    "        :param X: the input features to the model\n",
    "        :param y: the target feature\n",
    "        \"\"\"\n",
    "        \n",
    "        visualizer = Rank1D(algorithm='shapiro')\n",
    "\n",
    "        visualizer.fit(X, y)           # Fit the data to the visualizer\n",
    "        visualizer.transform(X)        # Transform the data\n",
    "        \n",
    "        fig = go.Figure(\n",
    "            go.Bar(\n",
    "                x = visualizer.ranks_,\n",
    "                y = visualizer.features_,\n",
    "                orientation='h'\n",
    "            )\n",
    "        )\n",
    "        return fig\n",
    "        \n",
    "    def generate_rad_viz(self, X, y, **kwargs):\n",
    "        \"\"\"\n",
    "        Given the entire feature-space, X, and target-space, y, \n",
    "        generates a RadViz plotly object.\n",
    "        \n",
    "        :param X: the input features to the model.\n",
    "        :param y: the target variables to the model.\n",
    "        \"\"\"\n",
    "        \n",
    "        # grabbing rows, columns, to later build out the radviz data set\n",
    "        nrows, ncols = X.shape\n",
    "        to_plot = {label: [[], []] for label in yb.classes}\n",
    "        \n",
    "        # locations of where to plot the feature names.\n",
    "        class_points = np.array(\n",
    "            [\n",
    "                (np.cos(t), np.sin(t)) for t in [2.0 * np.pi * (i / float(ncols)) for i in range(ncols)]\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # converting from Data Frame to numpy array if need be\n",
    "        sc = MinMaxScaler(feature_range=(0,1))    \n",
    "        X_scaled = sc.fit_transform(X)\n",
    "        \n",
    "        # Compute the locations of the scatter plot for each class\n",
    "        for i, row in enumerate(X_scaled):\n",
    "            row_ = np.repeat(np.expand_dims(row, axis=1), 2, axis=1)\n",
    "            xy = (class_points * row_).sum(axis=0) / row.sum()\n",
    "            #label = self.classes[j] for j in y\n",
    "            label = self.classes[y.values[i]]\n",
    "            #label = 'not_survived' if y.values[i] == 0 else 'survived'  #self._label_encoder[y[i]]\n",
    "            to_plot[label][0].append(xy[0])\n",
    "            to_plot[label][1].append(xy[1])\n",
    "\n",
    "        layout = go.Layout(yaxis = dict(\n",
    "                            scaleanchor = \"x\",\n",
    "                            #scaleratio = 1,\n",
    "                            range=[-1.1, 1.1]\n",
    "                        ),\n",
    "                        xaxis=dict(\n",
    "                            range=[-1.1, 1.1],\n",
    "                            #scaleratio = 1\n",
    "                        ),\n",
    "                )\n",
    "\n",
    "        fig = go.Figure(layout=layout)\n",
    "            \n",
    "        for lab in self.classes:\n",
    "            trace = go.Scatter(\n",
    "                x = to_plot[lab][0],\n",
    "                y = to_plot[lab][1],\n",
    "                mode = 'markers', \n",
    "                name = f'{lab}'\n",
    "            )\n",
    "            fig.add_trace(trace)\n",
    "        \n",
    "\n",
    "        class_trace = go.Scatter(\n",
    "            x = [class_points[i][0] for i in range(len(class_points))] + [class_points[0][0]],\n",
    "            y = [class_points[i][1] for i in range(len(class_points))] + [class_points[0][1]],\n",
    "            name = 'Features',\n",
    "            mode = 'lines+text',\n",
    "            text = [self.feature_names[i] for i in range(len(self.feature_names))]\n",
    "        )\n",
    "        \n",
    "        fig.add_trace(class_trace)\n",
    "\n",
    "        return fig\n",
    "    \n",
    "    def generate_roc_auc(self, X_train, y_train, X_test, y_test, **kwargs):\n",
    "        \"\"\"\n",
    "        Given the training and testing sets, computes the ROC AUC metrics\n",
    "        for the given model and returns a ROC AUC plotly figure.\n",
    "        \n",
    "        :param X_train: the training feature set.\n",
    "        :param y_train: the training target set.\n",
    "        :param X_test: the testing feature set.\n",
    "        :param y_test: the testing target set.\n",
    "        \"\"\"\n",
    "        \n",
    "        visualizer = ROCAUC(self.model, classes=self.classes)\n",
    "\n",
    "        visualizer.fit(X_train, y_train)\n",
    "        visualizer.score(X_test, y_test)\n",
    "        \n",
    "        roc_data = visualizer.tpr\n",
    "        \n",
    "        layout = go.Layout(yaxis = dict(\n",
    "                                scaleratio = 1,\n",
    "                                range=[-.1, 1]\n",
    "                            ),\n",
    "                            xaxis=dict(\n",
    "                                range=[-.1, 1],\n",
    "                                #scaleratio = 1\n",
    "                            ),\n",
    "                        )\n",
    "\n",
    "        fig = go.Figure(layout=layout)\n",
    "\n",
    "        for tr in roc_data.keys():\n",
    "            trace = go.Scatter(\n",
    "                x = [i / len(roc_data[tr]) for i in range(len(roc_data[tr]))],\n",
    "                y = roc_data[tr],\n",
    "                name = f'{tr}' if type(tr) != int else f'{yb.classes[tr]}',\n",
    "                line = dict(shape = 'hv')\n",
    "            )\n",
    "            fig.add_trace(trace)\n",
    "\n",
    "        lin_line = go.Scatter(\n",
    "            x = [0,1],\n",
    "            y = [0,1],\n",
    "            name = 'linear_line',\n",
    "            line = dict(dash='dash')\n",
    "        )\n",
    "\n",
    "        fig.add_trace(lin_line)\n",
    "        return fig\n",
    "    \n",
    "    def generate_pca_2d(self, X, y, scale=True, **kwargs):\n",
    "        \"\"\"\n",
    "        Given the entire feature and target sets, performs a 2D Principal\n",
    "        Component Analysis and returns a plotly figure\n",
    "        \n",
    "        :param X: model feature set.\n",
    "        :param y: model target set.\n",
    "        :param scale: bool indicating if you want to perform Standard Scaling.\n",
    "        \"\"\"\n",
    "        \n",
    "        if scale:\n",
    "            X = StandardScaler().fit_transform(X)\n",
    "\n",
    "        model = PCA(n_components = 2)\n",
    "        model.fit(X)\n",
    "        features = model.transform(X) \n",
    "        \n",
    "        layout = go.Layout(\n",
    "            xaxis=dict(title='PC<sub>1</sub>'),\n",
    "            yaxis=dict(title='PC<sub>2</sub>')\n",
    "        )\n",
    "        \n",
    "        fig = go.Figure(layout=layout)\n",
    "        \n",
    "        for class_ in range(len(self.classes)):\n",
    "            temp_x, temp_y = features[y == class_].T\n",
    "            \n",
    "            trace = go.Scatter(\n",
    "                x = temp_x,\n",
    "                y = temp_y,\n",
    "                name = f'{self.classes[class_]}',\n",
    "                mode = 'markers'\n",
    "            )\n",
    "            \n",
    "            fig.add_trace(trace)\n",
    "    \n",
    "        return fig\n",
    "    \n",
    "    \n",
    "    def generate_pca_3d(self, X, y, scale=True, **kwargs):\n",
    "        \"\"\"\n",
    "        Given the entire feature and target sets, performs a 3D Principal\n",
    "        Component Analysis and returns a plotly figure\n",
    "        \n",
    "        :param X: model feature set.\n",
    "        :param y: model target set.\n",
    "        :param scale: bool indicating if you want to perform Standard Scaling.\n",
    "        \"\"\"\n",
    "        \n",
    "        if scale:\n",
    "            X = StandardScaler().fit_transform(X)\n",
    "\n",
    "        model = PCA(n_components = 3)\n",
    "        model.fit(X)\n",
    "        features = model.transform(X) \n",
    "        \n",
    "        fig = go.Figure()\n",
    "        \n",
    "        for class_ in range(len(self.classes)):\n",
    "            temp_x, temp_y, temp_z = features[y == class_].T\n",
    "            \n",
    "            trace = go.Scatter3d(\n",
    "                x = temp_x,\n",
    "                y = temp_y,\n",
    "                z = temp_z,\n",
    "                name = f'{self.classes[class_]}',\n",
    "                mode = 'markers'\n",
    "            )\n",
    "            \n",
    "            fig.add_trace(trace)\n",
    "            \n",
    "        \n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yb = YellowBrick(model=model, feature_names=X.columns, classes=['not_survived', 'survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.generate_rank_1d(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cv.generate_rank_2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.generate_rad_viz(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.generate_roc_auc(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.generate_pca_2d(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.generate_pca_3d(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('../models/model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../models/X_train.npy', X_train)\n",
    "np.save('../models/X_test.npy', X_test)\n",
    "np.save('../models/y_train.npy', y_train)\n",
    "np.save('../models/y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
